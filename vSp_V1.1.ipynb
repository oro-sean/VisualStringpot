{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##### Visual String Pot\n",
    "# This program takes an image and finds the centre of an orange stripe and green dot. It then use the length of the orange stripe to scale the difference between the clusters to calculate the length.\n",
    "# it uses FAISS kmeans clustering to find a cluster of the approximate size of the stripe and dot.\n",
    "# the stripe and dot are then rotated onto the principle component of the stripe\n",
    "# the user defines a reduction and enchancment factotor which reduces the numbe rof pixcel and enchances the colours when the images are imported.\n",
    "# the uses then defines the window to focus clustering and the aprox dimensions of the striope and dot\n",
    "# the results are then exported as a csv with index, fileName, timeStamp, measurement, dotMedian, stripeMedian, scale, dotLength,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#### In version 1.1\n",
    "# image correction and scaling simplified\n",
    "# plotting impoved\n",
    "# hyperparmter entry streamlined\n",
    "# post calibration, offset and scaling\n",
    "# improved layout to add option for other clustering methods later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     54,
     69,
     83,
     110,
     148,
     159,
     195,
     218,
     240,
     289,
     309,
     338
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "def loadImages(directory, file_list, sample, reduction, enchanced, dim, ench_type):\n",
    "    ## Function takes file list and  if samples --> loads sample,\n",
    "    # otherwise loads all images in file list, reducing by the reduction factor and enchancing by the enchance factor.\n",
    "    # If dim --> crops image otherwise entire image is loaded\n",
    "\n",
    "    timeStamp = []  # create empty list for time stamps\n",
    "    index = 0  # set index to zero, used as counter for assignment  to array\n",
    "\n",
    "    if not sample:  # if sample does not exist create a list of numbers to load\n",
    "        sample = range(len(file_list))  # make sample the entire file list\n",
    "\n",
    "    if not dim:  # open an image and get the image dimensions if no cropping is supplied\n",
    "        image = np.array(Image.open(directory + file_list[0]).reduce(int((reduction))))  # load image to array\n",
    "        h, w, d = tuple(image.shape)  # get shape of image in file\n",
    "        dim = [0, h, 0, w, ]  # assign shape to dim list so entire image is imported\n",
    "\n",
    "    # Create empty NP array for pixcels. All pictures are loaded into an array height, width, # images, colours\n",
    "    pixcels = np.empty((dim[1] - dim[0],  # number of rows\n",
    "                        dim[3] - dim[2],  # number of columns\n",
    "                        len(sample),  # number of images\n",
    "                        3),  # number of colour arrays per image + 3 for x and y and l\n",
    "                       dtype='float32') # set data type as float 32 for faiss\n",
    "\n",
    "    for sam in sample:  # loop over each file in file_list\n",
    "        clear_output(wait=True)  # clear output\n",
    "        file = file_list[sam]  # set file as the sam'th entry in file list\n",
    "        file_path = directory + file  # define file path\n",
    "        ts = Image.open(file_path)._getexif()[36867]  # import timestamp as tS\n",
    "\n",
    "        if enchanced:  # if an enchancments is call\n",
    "            #open image and create enchancer\n",
    "            if ench_type == 'Bright':\n",
    "                enchancer = ImageEnhance.Brightness(Image.open(file_path).reduce(int((reduction))))\n",
    "                image = np.array(enchancer.enhance(enchanced))  # load image and convert to array\n",
    "\n",
    "            else:\n",
    "                enchancer = ImageEnhance.Contrast(Image.open(file_path).reduce(int((reduction))))\n",
    "                image = np.array(enchancer.enhance(enchanced))  # load image and convert to array\n",
    "\n",
    "        else:  # if no enchancement is called\n",
    "            image = np.array(Image.open(file_path).reduce(int((reduction))))  # load image into array\n",
    "\n",
    "        # crop array and load into pixcels array\n",
    "        pixcels[:, :, index, :] = image[dim[0]: dim[1],\n",
    "                                  dim[2]: dim[3],\n",
    "                                  :]\n",
    "\n",
    "        timeStamp.append(ts)  # append time stamp to list\n",
    "        index += 1 # increase index counter by 1\n",
    "        print(\"importing \" + file + \" file # \" + str(sam + 1) + \" of \" + str(len(file_list) + 1)) # print file number\n",
    "        print(ts) # print time stamp\n",
    "    return (timeStamp, pixcels)\n",
    "\n",
    "def determine_enchancement(in_dir, file_list, sample, reduction, enchancement, dim, ench_type, target_length):\n",
    "    ## Define function determines how much brightening is required for the provided subset.\n",
    "\n",
    "    avgLength = 0 # set avgLength variable as 0 to enter while loop\n",
    "    while avgLength < target_length: # continue to increase brightening while avgLength is less than target length\n",
    "        timeStamp, pixcels = loadImages(in_dir, file_list, sample, reduction, enchancement, dim, ench_type) # load target sample\n",
    "        avgLength = np.reshape(pixcels, (-1,3)) # reshape pixcels to just rgb from all images\n",
    "        lengths = [] # create empty list to append length to\n",
    "        for i in range(0,avgLength.shape[0]): # iterate over each pixcel and calculate the length\n",
    "            lengths.append(np.linalg.norm(avgLength[i])) # append pixcel length to the avgLength list\n",
    "        avgLength = sum(lengths)/len(lengths) # calulate overall average length\n",
    "\n",
    "        if avgLength < target_length: # if avg length is not large enough increace enchacemnt by 1\n",
    "            enchancement += 1\n",
    "\n",
    "    return enchancement\n",
    "\n",
    "def clus2Image(clussArr, centers, recolour_dict, scale):\n",
    "    ## define function to take an array of cluster labels and centers and return an image array, with specified clusters recoulured if required\n",
    "    if scale:\n",
    "        Scaler = MinMaxScaler(feature_range=(0,255)) # define minmax scaler to scale colours to 0 --> 255\n",
    "        centers = Scaler.fit_transform(centers)\n",
    "\n",
    "    if recolour_dict: # if recolour provided\n",
    "        for key in recolour_dict.keys(): # iterate over each key value pair\n",
    "            centers[key] = np.asarray(recolour_dict[key]) # change the value of that center to the specified colour\n",
    "\n",
    "    imgArr = centers[clussArr]\n",
    "\n",
    "    return(imgArr)\n",
    "\n",
    "def plotSamples(imgArray, ticks, title, titleData, scaleColours):\n",
    "    ## function image array and if required scales pixcel to 0-255\n",
    "    # Then plots images over 2 columns and as many rows as required. user selects if ticks and headings --> supply heading data in list form\n",
    "\n",
    "    if scaleColours: # if scaling colours is required\n",
    "        Scaler = MinMaxScaler(feature_range=(0,255)) # define minmax scaller to scale colours to 0 --> 255\n",
    "        imgArray = Scaler.fit_transform(imgArray) # scale image array RGB channels\n",
    "\n",
    "\n",
    "    sampleSize = imgArray.shape[2]  # return the 3rd dimension of the array as the number of images to plot\n",
    "    width = 2  # set number of columns to plot\n",
    "    height = int(sampleSize / width)  # determine how many rows to plot\n",
    "    index = 0  # set a counter to 0\n",
    "    plt.close()  # close previous plot\n",
    "    f, axarr = plt.subplots(height, width)  # create enough rows to plot all samples\n",
    "    for row in range(0, height):  # iterate over each image row\n",
    "        for h in range(0, height):  # iterare over each column\n",
    "            axarr[h, row].imshow(imgArray[:, :, index, :].astype('uint8'))  # open image and plot\n",
    "            if title:\n",
    "                axarr[h, row].title.set_text(titleData[row])\n",
    "\n",
    "            if not ticks:\n",
    "                axarr[h, row].set_xticks([])\n",
    "                axarr[h, row].set_yticks([])\n",
    "\n",
    "            index += 1  # increase counter by 1\n",
    "\n",
    "def faissCluster(pixcels, frac, startClus, noIt, reduction):\n",
    "    ## define function to perfrom kmeans clustering using faiss\n",
    "    no_clusters = startClus  # set inital number of clusters\n",
    "    no_iterations = noIt  # set the no of iterations for each step of kmeans\n",
    "    clusterMin = 1000  # set cluster min to enter while loop\n",
    "    restart = 0\n",
    "    pixcels = np.reshape(pixcels, (h*w*l,-1)) # reshape pixcels to a list of features\n",
    "    d = pixcels.shape[1] # record the length of each feature to for faiss clustering definition\n",
    "\n",
    "    if pixcels.dtype != 'float32': # check pixcel data type is suitable for faiss\n",
    "        pixcels = pixcels.astype('float32') # if required change data type\n",
    "        print(\"input array data type changed to \"+str(pixcels.dtype)) # print conformation that data type change\n",
    "\n",
    "    while clusterMin > frac:  # continue to increase number of clusters until the smallest cluster becomes sufficently small to just be the stripe\n",
    "        #clear_output(wait=True)  # clear output\n",
    "        print('clustering with ' + str(no_clusters) + \"\\n\")\n",
    "        kmeans = faiss.Kmeans(d, no_clusters, niter=no_iterations, verbose=True)  # define faiss kmeans object\n",
    "        kmeans.train(pixcels)  # train kmeans object\n",
    "        D, I = kmeans.index.search(pixcels, 1)  # return kmeans\n",
    "        pixInClus = np.unique(I, return_counts=True)  # get counts # pixels in each cluster\n",
    "        #colour = np.where(pixInClus[1] == min(pixInClus[1])) # assigns the smallest cluster as the stripe colour\n",
    "        colour = np.where(\n",
    "            abs(pixInClus[1] / pixInClus[1].sum() - frac) == abs(pixInClus[1] / pixInClus[1].sum() - frac).min())\n",
    "        clusterMin = min(pixInClus[1]) / (\n",
    "                    h * w * l)  # Calcultes the fraction of the picture occupied the the stripeColour\n",
    "        no_clusters += 1  # Increase number of clusters by 1\n",
    "\n",
    "        if clusterMin < 0.5 * frac: # check if cluster min is signifigantly smaller than the expected fraction\n",
    "            frac = 1.15 * frac # increase fraction so clustering stops slightly earlier to stop the last step being too large\n",
    "            no_clusters = startClus # restart the number of clusters\n",
    "            clusterMin = 1000 # restart cluster min to restart while loop\n",
    "\n",
    "        print(\"Cluster Min was \" + str(clusterMin) + \"\\n\") # print what the cluster min was\n",
    "\n",
    "    I = np.reshape(I, (h,w,l,1))\n",
    "\n",
    "    return (I, kmeans, colour[0])\n",
    "\n",
    "def get_colour_cosine(kmeans, target_colour):\n",
    "    ## define function to inspect all cluster centers and determine which has the closest cosine distance to the target colour\n",
    "\n",
    "    cosineDistance = [] # empty list to store cosine distances\n",
    "\n",
    "    for i in range(0,kmeans.centroids.shape[0]): # iterate over each centroid\n",
    "        cosineDistance.append(distance.cosine(kmeans.centroids[i,:], target_colour)) # append the cosine distance to target colour\n",
    "\n",
    "    trgCluster = np.where(cosineDistance == min(cosineDistance)) # find the closest\n",
    "    trgCluster = trgCluster[0] # return single row of array for easy handling\n",
    "\n",
    "    return trgCluster\n",
    "\n",
    "def norm_to_target(labels, imgArray, trgClus, trg):\n",
    "    ## Define function to normalise each image so as the target clusters appear similar for each image\n",
    "\n",
    "    noStripe = 0 # set number of images not containing a pixcel clustered to the stripe colour\n",
    "\n",
    "    imgArray = np.reshape(imgArray,(-1,l,3), order='F') # reshape fortran style so as each photo is a list of vectors\n",
    "\n",
    "    ## find stripe mean and the picture mean\n",
    "    if trg: # if normalising based on stripe colour\n",
    "        labels = np.reshape(labels,(-1,l), order='F') # reshape labels fortran style so as each image is a list of labels\n",
    "        picMeans_orig = [] # create empty list to append each picture mean\n",
    "        for i in range(0,l): # iterate over each picture\n",
    "            if np.where(labels[:,i] == trgClus)[0].shape[0] > 10: # check image contains atleast 10 stripe pixcels\n",
    "                picMean = list(imgArray[np.where(labels[:,i] == trgClus),i,:].mean(axis=0)[0]) # calculate the mean value of the pixcels that are in stripe\n",
    "                picMeans_orig.append(picMean) # append this mean to pic mean\n",
    "\n",
    "            else: # if no stripe pixcels are found append the avergae of the previous photo\n",
    "                picMeans_orig.append(picMean)\n",
    "                print(\"used Last pic mean \"+str(picMean)+\" for image number \"+str(i))\n",
    "                noStripe +=1\n",
    "\n",
    "        picMeans_orig = np.array(picMeans_orig) # make picMeans_orig an array\n",
    "        stripe_mean = picMeans_orig.mean(axis=0) # calculate stripe means by finding the average of pic means\n",
    "        meanModifer = np.subtract(np.transpose(np.reshape(np.tile(stripe_mean, l),(3,l), order='F')),picMeans_orig) # determine the mean modifier\n",
    "\n",
    "        for i in range(0,l): # iterate over each image\n",
    "            imgArray[:,i,:] = np.transpose(np.transpose(imgArray[:,i,:])+np.reshape(np.repeat(meanModifer[i,:], h*w, axis=0), (d,h*w))) # apply the mean modifier\n",
    "\n",
    "    imgArray[np.where(imgArray < 0)] = 0 # find anywhere the the rgb has gone below 0 and replace with 0\n",
    "    imgArray = np.reshape(imgArray,(h*w*l,d)) # reshape img array to list of pixcels\n",
    "    pixcelSums = imgArray.sum(axis=1) # find the sum of each pixcel\n",
    "    pixcelSums[np.where(pixcelSums == 0)] = 1 # where the pixcel sum is 0 replace with 1 to avoid dev by 0 error, it wont matter as 0/1 = 0\n",
    "    pixcelSums = np.reshape(np.tile(pixcelSums,3), (h*w*l,d), order='F') # reshape to correct shape\n",
    "    imgArray = np.divide(imgArray, pixcelSums) # normalise by dividing by sum\n",
    "    imgArray = np.reshape(np.reshape(imgArray,(h*w,l,d)), (h,w,l,d), order='F') # reshape to hand back to\n",
    "\n",
    "    return imgArray, noStripe\n",
    "\n",
    "def cleanIQR(upper, lower, singleValues, inplace, verb):\n",
    "    iqr = np.subtract(*np.percentile(singleValues, [75, 25])) # calculate the interquartile range\n",
    "    minus = np.percentile(singleValues, 25) - lower * iqr # calculate the lower bound as lower x iqr from the 25th percentile\n",
    "    plus = np.percentile(singleValues, 75) + upper * iqr # calculate the upper bound as upper x iqr from the 75th percentile\n",
    "    toKeep = (minus < singleValues) & (singleValues < plus) # create list of logicals defining which values to keep\n",
    "    if verb: # if verb create box plots\n",
    "        plt.close()\n",
    "        f, axarr = plt.subplots(2)  # create enough rows to plot all samples\n",
    "        axarr[0].boxplot(singleValues)\n",
    "        axarr[1].boxplot(singleValues[(minus < singleValues) & (singleValues < plus)])\n",
    "        print('The min projected y value before cleaning is ' + str(singleValues.min()))\n",
    "        print('The max projected y value before cleaning is ' + str(singleValues.max()))\n",
    "        print('The min projected y value after cleaning is ' +\n",
    "              str(singleValues[(minus < singleValues) & (singleValues < plus)].min()))\n",
    "        print('The max projected y value after cleaning is ' +\n",
    "              str(singleValues[(minus < singleValues) & (singleValues < plus)].max()))\n",
    "\n",
    "    if inplace: # if inplace return the vales to keep only\n",
    "        return (singleValues[(minus < singleValues) & (singleValues < plus)])\n",
    "    else: # otherwsie return the logical list for filtering out of this function\n",
    "        return (toKeep)\n",
    "\n",
    "def find_rotation(coords):\n",
    "    # define the IQR range to use when cleaning values prior to calculating rotation matrix\n",
    "    perpClean_min = 1.5 # IQR to use to filter perpendicular to stripe\n",
    "    perpClean_max = 1.5\n",
    "    rotClean_min = 1.5 # IQR to use to filter values along the stripe\n",
    "    rotClean_max = 1.5\n",
    "    n=0\n",
    "    while n < 2: # repeat twice so as outliers to not affect the rotation matrix\n",
    "        pca = PCA(2) #define pca\n",
    "        pca.fit(coords[0:2,:].T) # fit pca to the stripe cordinates\n",
    "        Vh = pca.components_ # find rotation vector\n",
    "        stripe_perp = coords[0:2,:].T @ Vh[:,1] # rotate stripe onto second principle component of stripe to clean\n",
    "        stripe_perp = cleanIQR(perpClean_max,perpClean_min,stripe_perp, False, True) # remove outliers from stripe rot\n",
    "        stripe_rot = coords[0:2,:].T @ Vh[:,0] # rotate stripe onto first principle component\n",
    "        stripe_rot = stripe_rot[stripe_perp]\n",
    "        coords = coords[:, stripe_perp]\n",
    "        stripe_rot = cleanIQR(rotClean_max,rotClean_min,stripe_rot, False, True) # clean IQR\n",
    "        coords = coords[:,stripe_rot]\n",
    "        n += 1 # increase counter by 1\n",
    "\n",
    "    print(\"Stripe is roated \"+str(math.acos(Vh[0,0]))+\" degrees\")\n",
    "    return(Vh, coords)\n",
    "\n",
    "def cluster_length(coordinates, Vh):\n",
    "    ## Define function to find the length of clustered pixcels along the principle component.\n",
    "    imgNo = []\n",
    "    start_list = []\n",
    "    stop_list = []\n",
    "    length_list = []\n",
    "    prob_list = []\n",
    "    start_grad = []\n",
    "    stop_grad = []\n",
    "    fail = []\n",
    "    for i in range(0,l):\n",
    "        clear_output(wait=True)\n",
    "        print(\"calculating cluster length for image #\"+str(i)+\"of\"+str(l))\n",
    "        try:\n",
    "            \n",
    "            pic = coordinates[0:2,np.where(coordinates[2,:] == i)[0]] # select from single photo\n",
    "            pic = np.transpose(np.matmul(np.transpose(pic), Vh)) # transpose and mulitiply by rotation matrix\n",
    "            pic = abs(np.rint(pic[0,:]).astype('int')) # round and multiply by negative 1\n",
    "            count = np.bincount(pic) # count how many occourences for each x value\n",
    "            start = np.where(np.diff(count) == np.diff(count).max())[0][0]\n",
    "            stop = np.where(np.diff(count) == np.diff(count).min())[0][0]\n",
    "            length = stop - start\n",
    "            m = count.max() # assume the highest count is actually the full stripe\n",
    "            prob = count / m # calculate the probability of each x observation actually being a stripe\n",
    "            stripeProb = prob[start:stop].sum()/len(prob[start:stop])\n",
    "            \n",
    "            start_list.append(start)\n",
    "            stop_list.append(stop)\n",
    "            prob_list.append(stripeProb)\n",
    "            length_list.append(length)\n",
    "            start_grad.append(np.diff(count)[np.where(np.diff(count) == np.diff(count).max())[0][0]])\n",
    "            stop_grad.append(np.diff(count)[np.where(np.diff(count) == np.diff(count).min())[0][0]])\n",
    "            imgNo.append(i)\n",
    "\n",
    "        except:\n",
    "            start_list.append(float(\"nan\"))\n",
    "            stop_list.append(float(\"nan\"))\n",
    "            prob_list.append(float(\"nan\"))\n",
    "            length_list.append(float(\"nan\"))\n",
    "            start_grad.append(float(\"nan\"))\n",
    "            stop_grad.append(float(\"nan\"))\n",
    "            imgNo.append(i)\n",
    "            \n",
    "    percentileLimit = np.nanpercentile(np.array(prob_list), 95)\n",
    "    goodSample = np.where(np.array(prob_list) > percentileLimit)\n",
    "    lengths = np.asarray(length_list)\n",
    "    clusLength = np.median(lengths[goodSample])\n",
    "\n",
    "    Stats_df = pd.DataFrame({'image': imgNo,\n",
    "                             'start': start_list,\n",
    "                             'stop': stop_list,\n",
    "                             'length': length_list,\n",
    "                             'probability': prob_list,\n",
    "                             'startGrad': start_grad,\n",
    "                             'stopGrad': stop_grad})\n",
    "    \n",
    "    return Stats_df, clusLength\n",
    "\n",
    "def getMiddle(stats_df, length, label):\n",
    "    length_logical = stats_df.length > 0.9 * length\n",
    "    probs_logical = stats_df.probability > 0.9\n",
    "    start_logical = abs(stats_df.startGrad) / abs(stats_df.stopGrad) > 0.75\n",
    "    stop_logical = abs(stats_df.stopGrad) / abs(stats_df.startGrad) > 0.75\n",
    "    stats_df['useMean'] = list(map(all, zip(length_logical,probs_logical, start_logical, stop_logical)))\n",
    "    mid = []\n",
    "    for index, row in stats_df.iterrows():\n",
    "        if row['useMean']:\n",
    "            mid.append((row['start']+row['stop'])/2)\n",
    "        else:\n",
    "            if abs(row['startGrad']) > abs(row['stopGrad']):\n",
    "                mid.append(row['start']+ 0.5 * length)\n",
    "            else:\n",
    "                mid.append(row['stop']- 0.5 * length)\n",
    "\n",
    "    stats_df[label] = mid\n",
    "    \n",
    "    return(stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import time\n",
    "import faiss\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from scipy.fft import fft, fftfreq, ifft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## define working directory and which files to sample\n",
    "in_dir = '/mnt/veeringDL_storage/test_9/' # define directory containing all gopro images\n",
    "out_dir = '/mnt/home/9.0 Data Jobs/' # define output directory\n",
    "file_list = [f for f in listdir(in_dir) if isfile(join(in_dir, f))] # inspect directory and return list of files\n",
    "print(str(len(file_list))+' Images found in folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## user defines which images to sample, trget size, enchancemt factor and type\n",
    "sample = [10,4000,7000,10000] # Set which 4 images to sample\n",
    "## make this a fraction of gopro ??\n",
    "targetSize = 1200000 # define target size in pixcels\n",
    "enchancement = 1 # define enchancement value\n",
    "ench_type = 'Bright' # define enchancement type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## load sample images and plot\n",
    "timeStamp, pixcels = loadImages(in_dir, file_list, [0], 1, False, False, False) # load a single image at full resolution\n",
    "h, w, l, d = orig_shape = tuple(pixcels.shape) # return the dimensions of the original image\n",
    "reduction = int((h*w)/targetSize) # caclulate the required reduction\n",
    "print('A reduction factor of '+str(reduction)+' was adopted')\n",
    "timeStamp, pixcels = loadImages(in_dir, file_list, sample, reduction, enchancement, False, ench_type)\n",
    "plotSamples(pixcels, True, False, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## User defines where to crop image\n",
    "h1 = 120 # horizontal (x) to start image at\n",
    "h2 = 315 # horizontal (x) to end image at\n",
    "v1 = 135 # vertical (y) to start image at\n",
    "v2 = 230 # vertical (y) to end image at\n",
    "dim = [v1, v2, h1, h2] # make dim variable as list to pass to load images\n",
    "enchancement = 1 # define enchancement value\n",
    "ench_type = 'Bright' # define enchancement type\n",
    "targetPixcelLength = 200 # define the target pixcel length\n",
    "enchancement_value = determine_enchancement(in_dir, file_list, sample, reduction, enchancement, dim, ench_type, targetPixcelLength)\n",
    "timeStamp, pixcels = loadImages(in_dir, file_list, sample, reduction, enchancement_value, dim, ench_type)\n",
    "print(\"Brightness used \"+str(enchancement_value))\n",
    "plotSamples(pixcels, True, False, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stripe_left = 106 # left bound of stripe\n",
    "stripe_right = 189 # right bound of stripe\n",
    "stripe_top = 65 # top bound of stripe\n",
    "stripe_bottom = 83 # bottom bound of stripe\n",
    "dot_left = 32 # left bound dot\n",
    "dot_right =62 # right bound of dot\n",
    "dot_top =13 # top bound of dot\n",
    "dot_bottom = 33 # bottom bound of dot\n",
    "area_factor = 1.1 # factor to multiply aproximmated area by\n",
    "stepAfterStripeCluss = 1 # number of clusters to increase after completion of stripe cluster\n",
    "stripe_area = abs(stripe_right - stripe_left) * abs(stripe_bottom - stripe_top) # calcluate area of stripe in pixcels\n",
    "dot_area = abs(dot_right - dot_left) * abs(dot_bottom - dot_top) # calculate area of dot in pixcels\n",
    "fig_area = abs(v2-v1) * abs(h2-h1) # calculate area of figure with\n",
    "stripeFrac = area_factor * stripe_area / fig_area # expected fraction of image to be the stripe\n",
    "dotFrac = area_factor * dot_area / fig_area # expected fraction of image to be the dot\n",
    "\n",
    "print(\"The stripe fraction used is \"+str(stripeFrac))\n",
    "print(\"the dot fraction used is \"+str(dotFrac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## define the number of iterations and # clusters to start with for faiss Kmeans\n",
    "it = 10 # # interations to perform in clustering\n",
    "stripe_startNo = 1 # number of initial clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pixcels = allImages ## HANDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## load all images, create image array to save RGB array before scaling and save original input array dimensions to rebuild later\n",
    "timeStamp, pixcels = loadImages(in_dir, file_list, False, reduction, enchancement_value, dim, ench_type)\n",
    "#allImages = pixcels # save original RGB pixcels for plotting latter\n",
    "h, w, l, d = orig_shape = tuple(pixcels.shape) # get shape of pixcels array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## perform rg chromacity on all images and plot the results\n",
    "features, noStripe = norm_to_target(False,pixcels,False,False) # perform only rg chromacity on all pixcles to create feature array\n",
    "plotSamples(features[:,:,sample,:]*255, False, False, False, False) # plot the resulting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Perfrom kmeans clustering using fais on the features to find the stripes\n",
    "I, kmeans, stripeColour =  faissCluster(features, stripeFrac, stripe_startNo, it, False) # perform faiss clustering looking for stripe\n",
    "stripeColour = get_colour_cosine(kmeans, [255,169,0]) # find the cluster label with the centre closest to the target colour using cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imgArr = clus2Image(I, kmeans.centroids[:,0:3], {stripeColour[0]: [0,1,0]}, False)  # convert labels and centroids to image arrays\n",
    "imgArr = np.reshape(imgArr, orig_shape) # reshape for plotting\n",
    "plotSamples(imgArr[:,:,sample,:]*255, False, False, False, False) # plot resulting clsuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## use know stripe locations to normalise colour accross data set using mean translate and then rgb chormisation\n",
    "features, noStripe = norm_to_target(I,pixcels,stripeColour, True) # renormalise with colour adjustment\n",
    "plotSamples(features[:,:,sample,:]*255, True, False, False, False) # plot normalised images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## recluster using improved features\n",
    "I, kmeans, stripeColour =  faissCluster(features, stripeFrac, 1, it, noStripe/l) # rerun kmeans on normalised pixcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## check the cluster found as the stripe is closest in colour to what was expected\n",
    "stripeColour_cosine = get_colour_cosine(kmeans, [255,169,0]) # find stripe colour using cosine distance\n",
    "if stripeColour_cosine != stripeColour:\n",
    "    print(\"Error, the cluster found for stripes is inconsitent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## plot final stripe clusters\n",
    "imgArr = clus2Image(I, kmeans.centroids[:,0:3], {stripeColour[0]: [0,255,0]}, False) # convert cluster labels and centres to image array with stripe cluster highlighted green\n",
    "imgArr = np.reshape(imgArr, orig_shape) # reshape to suit plotting\n",
    "plotSamples(imgArr[:,:,sample,:], False, False, False, False) # plot samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## use PCA to find the long edge of the stripe and project coordinates onto this axis and find statistical properties\n",
    "stripe_coords = np.array(np.where(np.reshape(I, (h,w,l)) == stripeColour)) # get stripe locations from reshaped labels array\n",
    "Vh, stripe_coords_clean = find_rotation(stripe_coords) # use find rotation to find the roation matrix to make x axis align with the longest edge\n",
    "stripeStats_df, stripeLength = cluster_length(stripe_coords_clean, Vh) # use cluster_length to build the stripe stats df and find the length of the stripe in pixcels\n",
    "stripeStats_df = getMiddle(stripeStats_df, stripeLength, \"stripe\") # use getMiddle to find the middle of the stripes and update stripes df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## recluster using faiss kmeans to find the dot clusters\n",
    "I, kmeans, dotColour =  faissCluster(features, dotFrac, stripe_startNo, it, noStripe/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## check the cluster found as dot colour is the closest to the expected colour\n",
    "dotColour_cosine = get_colour_cosine(kmeans, [0,256,0]) # find dot colour using cosine distance\n",
    "if dotColour_cosine != dotColour:\n",
    "    print(\"Error, the cluster found for dots is inconsitent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imgArr = clus2Image(I, kmeans.centroids[:,0:3], {dotColour[0]: [0,255,0]}, False) # use cluster labels and centroids to build image arrays\n",
    "imgArr = np.reshape(imgArr, orig_shape) # reshape to suit plotting\n",
    "plotSamples(imgArr[:,:,sample,:], False, False, False, False) # plot sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dot_coords = np.array(np.where(np.reshape(I, (h,w,l)) == dotColour)) # get stripe locations from reshaped labels array\n",
    "Vdot, dot_coords_clean = find_rotation(dot_coords) # find the cleaned dot cordinates and the rotation matrix\n",
    "dotStats_df, dotLength = cluster_length(dot_coords_clean , Vh) # use cluster_length to find the legth if the dot and the dot stats_df\n",
    "dotStats_df = getMiddle(dotStats_df, dotLength, \"dot\") # use get middle to find the midle of the dots and append it to the dotStats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stats_df = pd.merge(stripeStats_df, dotStats_df, on = 'image') # merge the 2 stats df on image for easy computation\n",
    "measure = stats_df['stripe'] - stats_df['dot'] # find difference between the centre of the stripe and the centre of the dot\n",
    "dataOut = pd.DataFrame({'time':timeStamp, 'measure':measure}) # build new data frame with just time and the measurement\n",
    "dataOut = dataOut.sort_values('time') # sort values by time\n",
    "plt.close()\n",
    "plt.plot(dataOut.time,dataOut.measure) # create a time series plot of the measured values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## use FFT to clean outliers from data\n",
    "dataOut.dropna(axis=0, how='any', inplace=True) # drop NA's\n",
    "x = np.array(list(dataOut.measure)) # create array of measurements\n",
    "y =  np.array(list(dataOut.time)) # create array of time stamps\n",
    "xf = fft(x) # fft x\n",
    "yf = fftfreq(len(y),1) # find freqencies\n",
    "plt.close()\n",
    "plt.plot(yf,xf) # plot fourier transformed data vs frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xf_abs = np.abs(xf) # find absolute values of fft\n",
    "indicies = xf_abs > 1000 # find indicies where freqency is greater\n",
    "xf_clean = indicies * xf # clean data using indicies filter\n",
    "plt.close()\n",
    "plt.plot(yf, np.abs(xf_clean)) # plot cleaned fourier transformed data vs frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_f_clean = ifft(xf_clean) # inverse FFT for the cleaned values\n",
    "plt.close()\n",
    "plt.plot(y, new_f_clean) # plot the new time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## use residual from rolling mean and standard deviation to smooth time serries data\n",
    "avg = pd.Series(new_f_clean) # create a pandas series of all measurements from the FFT cleaning\n",
    "avg = avg.rolling(5).mean() # calculate the rolling 5 second mean\n",
    "std = pd.Series(new_f_clean) # create a pandas series of all measurements from the FFT cleaning\n",
    "avg = std.rolling(5).std() # calculate the rolling 5 second standard deviation\n",
    "residuals = pd.Series(new_f_clean) - avg\n",
    "\n",
    "residuals = residuals > std\n",
    "\n",
    "plt.close()\n",
    "plt.plot(y, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## define known geometry\n",
    "knownLength = -87 # known length of the stripe, negative if measure should get larger when dot is closer to stripe\n",
    "offset = -127.5 # known zero offset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "1060.85px",
    "left": "2105.17px",
    "right": "20px",
    "top": "27px",
    "width": "665.667px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}